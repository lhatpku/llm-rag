llm: "llama-3.1-8b-instant"

vectordb:
  threshold: 0.3
  n_results: 5

memory_strategies:
  trimming_window_size: 6 # Number of messages to keep in trimming strategy (6 would be 3 pairs of Q/A)
  summarization_max_tokens: 1000 # Max tokens before summarization kicks in